{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from configs.parser import YAMLParser\n",
    "import mlflow\n",
    "from dataloader.h5 import H5Loader\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from loss.flow import FWL, RSAT, AEE\n",
    "from utils.utils import load_model\n",
    "from models.model import (\n",
    "    FireNet,\n",
    "    RNNFireNet,\n",
    "    LeakyFireNet,\n",
    "    FireFlowNet,\n",
    "    LeakyFireFlowNet,\n",
    "    E2VID,\n",
    "    EVFlowNet,\n",
    "    RecEVFlowNet,\n",
    "    LeakyRecEVFlowNet,\n",
    "    RNNRecEVFlowNet,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "runid = \"EVFlowNet\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"\")\n",
    "run = mlflow.get_run(runid)\n",
    "config_parser = YAMLParser(\"configs/eval_MVSEC.yml\")\n",
    "config = config_parser.config\n",
    "config = config_parser.merge_configs(run.data.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = H5Loader(config, config[\"model\"][\"num_bins\"])\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "        data,\n",
    "        drop_last=True,\n",
    "        batch_size=config[\"loader\"][\"batch_size\"],\n",
    "        collate_fn=data.custom_collate,\n",
    "        worker_init_fn=config_parser.worker_init_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_flow(flow):\n",
    "    hsv = np.zeros((flow.shape[1], flow.shape[2], 3), dtype=np.uint8)\n",
    "    hsv[..., 1] = 255\n",
    "    mag, ang = cv2.cartToPolar(flow[0,...].numpy(), flow[1,...].numpy())\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_number = 0\n",
    "flow = data[data_number][\"gtflow\"]\n",
    "\n",
    "\n",
    "plt.imshow(visualize_flow(flow))\n",
    "for ev in data[data_number][\"event_list\"].transpose(1, 0):\n",
    "    plt.scatter(ev[1], ev[2], s=5, c=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEE_HIST(AEE):\n",
    "    \n",
    "    def __init__(self, config, device, flow_scaling=128):\n",
    "        super().__init__(config, device, flow_scaling)\n",
    "        self._masked_error_list = None\n",
    "        self._masked_gtflow_list = None\n",
    "    \n",
    "    def mask_for_flow(self):\n",
    "        event_mask = self._event_mask[:, -1, :, :].bool()\n",
    "        gtflow_mask_x = self._gtflow[:, 0, :, :] == 0.0\n",
    "        gtflow_mask_y = self._gtflow[:, 1, :, :] == 0.0\n",
    "        gtflow_mask = gtflow_mask_x | gtflow_mask_y\n",
    "        gtflow_mask = ~gtflow_mask\n",
    "        mask = event_mask & gtflow_mask\n",
    "        return mask.squeeze()\n",
    "    \n",
    "    def masked_optical_flow(self,flow, mask):\n",
    "        masked_flow = flow[:,:,mask]\n",
    "        masked_gtflow = self._gtflow[:,:,mask]\n",
    "        masked_error = masked_flow - masked_gtflow\n",
    "        return masked_error.detach().cpu(), masked_gtflow.detach().cpu()\n",
    "    \n",
    "    def flow_accumulation(self):\n",
    "        flow = self._flow_map[-1] * self.flow_scaling\n",
    "        flow *= self._dt_gt.to(self.device) / self._dt_input.to(self.device)\n",
    "        mask = self.mask_for_flow()\n",
    "        masked_error, masked_gtflow = self.masked_optical_flow(flow, mask)\n",
    "        if self._masked_error_list is None:\n",
    "            self._masked_error_list = [masked_error]\n",
    "        else:\n",
    "            self._masked_error_list.append(masked_error)\n",
    "        if self._masked_gtflow_list is None:\n",
    "            self._masked_gtflow_list = [masked_gtflow]\n",
    "        else:\n",
    "            self._masked_gtflow_list.append(masked_gtflow)\n",
    "    \n",
    "    def optical_flow_vec2scalar(self, flow, reduce_norm='L2'):\n",
    "        flow = torch.cat(flow, dim=2)\n",
    "        if reduce_norm == 'L1':\n",
    "            return torch.sum(torch.abs(flow), dim=1)\n",
    "        elif reduce_norm == 'L2':\n",
    "            return torch.sqrt(torch.sum(flow**2, dim=1))\n",
    "            \n",
    "    def calculate_error_hist(self,n_bins=10):\n",
    "        gtflow_mag = self.optical_flow_vec2scalar(self._masked_gtflow_list).view(-1)\n",
    "        error_mag = self.optical_flow_vec2scalar(self._masked_error_list).view(-1)\n",
    "        # Compute histogram and bin centers\n",
    "        hist, bin_edges = torch.histogram(gtflow_mag, bins=n_bins)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "        # Compute mean and standard deviation for each bin\n",
    "        mean_values = []\n",
    "        std_values = []\n",
    "        for i in range(n_bins):\n",
    "            idx = torch.where((gtflow_mag >= bin_edges[i]) & (gtflow_mag < bin_edges[i+1]))\n",
    "            mean_values.append(torch.mean(error_mag[idx]))\n",
    "            std_values.append(torch.std(error_mag[idx]))\n",
    "            \n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.bar(bin_centers, hist, width=bin_centers[1]-bin_centers[0], color='gray', alpha=0.5)\n",
    "        ax.errorbar(bin_centers, mean_values, yerr=std_values, fmt='o', color='black')\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_title('Histogram with Mean and Standard Deviation')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored from EVFlowNet\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/pyg-new/lib/python3.10/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'models.unet.MultiResUNetRecurrent' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/pyg-new/lib/python3.10/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/pyg-new/lib/python3.10/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'models.submodules.RecurrentConvLayer' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/pyg-new/lib/python3.10/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'models.submodules.ConvLayer' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/pyg-new/lib/python3.10/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "device = config_parser.device\n",
    "model = eval(config[\"model\"][\"name\"])(config[\"model\"]).to(device)\n",
    "model = load_model(runid, model, device)\n",
    "model.eval()\n",
    "aee_hist = AEE_HIST(config, device, flow_scaling=config[\"metrics\"][\"flow_scaling\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sequence:  0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.95 GiB total capacity; 3.22 GiB already allocated; 3.31 MiB free; 3.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# forward pass\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m x \u001b[39m=\u001b[39m model(\n\u001b[1;32m     19\u001b[0m     inputs[\u001b[39m\"\u001b[39;49m\u001b[39mevent_voxel\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device), inputs[\u001b[39m\"\u001b[39;49m\u001b[39mevent_cnt\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device), log\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mvis\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mactivity\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m aee_hist\u001b[39m.\u001b[39mevent_flow_association(x[\u001b[39m\"\u001b[39m\u001b[39mflow\u001b[39m\u001b[39m\"\u001b[39m], inputs)   \n\u001b[1;32m     23\u001b[0m val_metrics\u001b[39m.\u001b[39mappend(aee_hist())\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/pyg-new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/event-based-optical-flow/event_flow/models/model.py:520\u001b[0m, in \u001b[0;36mRecEVFlowNet.forward\u001b[0;34m(self, event_voxel, event_cnt, log)\u001b[0m\n\u001b[1;32m    517\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop\u001b[39m.\u001b[39mpad(x)\n\u001b[1;32m    519\u001b[0m \u001b[39m# forward pass\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m multires_flow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultires_unetrec\u001b[39m.\u001b[39;49mforward(x)\n\u001b[1;32m    522\u001b[0m \u001b[39m# log activity\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39mif\u001b[39;00m log:\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/event-based-optical-flow/event_flow/models/unet.py:398\u001b[0m, in \u001b[0;36mMultiResUNetRecurrent.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    396\u001b[0m blocks \u001b[39m=\u001b[39m []\n\u001b[1;32m    397\u001b[0m \u001b[39mfor\u001b[39;00m i, encoder \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoders):\n\u001b[0;32m--> 398\u001b[0m     x, state \u001b[39m=\u001b[39m encoder(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstates[i])\n\u001b[1;32m    399\u001b[0m     blocks\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m    400\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates[i] \u001b[39m=\u001b[39m state\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/pyg-new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/event-based-optical-flow/event_flow/models/submodules.py:232\u001b[0m, in \u001b[0;36mRecurrentConvLayer.forward\u001b[0;34m(self, x, prev_state)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, prev_state):\n\u001b[1;32m    231\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(x)\n\u001b[0;32m--> 232\u001b[0m     x, state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecurrent_block(x, prev_state)\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecurrent_block, ConvLSTM):\n\u001b[1;32m    234\u001b[0m         state \u001b[39m=\u001b[39m (x, state)\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/envs/pyg-new/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/tudelft.net/staff-bulk/ewi/insy/VisionLab/maraghi/event-based-optical-flow/event_flow/models/submodules.py:416\u001b[0m, in \u001b[0;36mConvGRU.forward\u001b[0;34m(self, input_, prev_state)\u001b[0m\n\u001b[1;32m    414\u001b[0m reset \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_gate(stacked_inputs))\n\u001b[1;32m    415\u001b[0m out_inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtanh(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_gate(torch\u001b[39m.\u001b[39mcat([input_, prev_state \u001b[39m*\u001b[39m reset], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)))\n\u001b[0;32m--> 416\u001b[0m new_state \u001b[39m=\u001b[39m prev_state \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m update) \u001b[39m+\u001b[39m out_inputs \u001b[39m*\u001b[39;49m update\n\u001b[1;32m    418\u001b[0m \u001b[39mreturn\u001b[39;00m new_state, new_state\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.95 GiB total capacity; 3.22 GiB already allocated; 3.31 MiB free; 3.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "end_test = False\n",
    "c = 0\n",
    "val_metrics = []\n",
    "print(\"New sequence: \", data.seq_num)\n",
    "while True:\n",
    "    \n",
    "    for inputs in dataloader:\n",
    "        \n",
    "        if data.new_seq or c == 2000:\n",
    "            data.new_seq = False\n",
    "            activity_log = None\n",
    "            model.reset_states()\n",
    "            print(\"New sequence: \", data.seq_num)\n",
    "            end_test = True\n",
    "            break\n",
    "        \n",
    "        # forward pass\n",
    "        x = model(\n",
    "            inputs[\"event_voxel\"].to(device), inputs[\"event_cnt\"].to(device), log=config[\"vis\"][\"activity\"]\n",
    "        )\n",
    "        \n",
    "        aee_hist.event_flow_association(x[\"flow\"], inputs)   \n",
    "        val_metrics.append(aee_hist())\n",
    "        c += 1\n",
    "\n",
    "        aee_hist.flow_accumulation()\n",
    "        aee_hist.reset()\n",
    "        # finish inference loop\n",
    "        if data.seq_num >= len(data.files):\n",
    "            end_test = True\n",
    "            break\n",
    "    \n",
    "    if end_test:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([4.5629], device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>), tensor([0.6000], device='cuda:0'))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'pow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(val_metrics[\u001b[39m0\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(aee_hist\u001b[39m.\u001b[39;49m_masked_error_list[\u001b[39m0\u001b[39;49m:]\u001b[39m.\u001b[39;49mpow(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msqrt()\u001b[39m.\u001b[39mmean())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'pow'"
     ]
    }
   ],
   "source": [
    "print(val_metrics[0])\n",
    "print(aee_hist._masked_error_list[0].pow(2).sum(dim=1).sqrt().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 20\n",
    "gtflow_mag = aee_hist.optical_flow_vec2scalar(aee_hist._masked_gtflow_list).view(-1)\n",
    "error_mag = aee_hist.optical_flow_vec2scalar(aee_hist._masked_error_list).view(-1)\n",
    "# Compute histogram and bin centers\n",
    "hist, bin_edges = torch.histogram(gtflow_mag, bins=n_bins)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Compute mean and standard deviation for each bin\n",
    "mean_values = []\n",
    "std_values = []\n",
    "for i in range(n_bins):\n",
    "    idx = torch.where((gtflow_mag >= bin_edges[i]) & (gtflow_mag < bin_edges[i+1]))\n",
    "    mean_values.append(torch.mean(error_mag[idx]))\n",
    "    std_values.append(torch.std(error_mag[idx]))\n",
    "    \n",
    "# Create plot\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.bar(bin_centers, hist/gtflow_mag.shape[0], width=bin_centers[1]-bin_centers[0], color='gray', alpha=0.5)\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('histogram of GT flow magnitude')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.errorbar(bin_centers, mean_values, yerr=std_values, fmt='o', color='black')\n",
    "ax2.set_ylabel('AEE')\n",
    "ax.set_title('Histogram with Mean and Standard Deviation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample data\n",
    "data = np.random.randn(100, 2)  # Replace this with your own data\n",
    "\n",
    "# Define histogram parameters\n",
    "n_bins = 10\n",
    "x_column = 0\n",
    "\n",
    "# Compute histogram and bin centers\n",
    "hist, bin_edges = np.histogram(data[:, x_column], bins=n_bins)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Compute mean and standard deviation for each bin\n",
    "mean_values = []\n",
    "std_values = []\n",
    "for i in range(n_bins):\n",
    "    idx = np.where((data[:, x_column] >= bin_edges[i]) & (data[:, x_column] < bin_edges[i+1]))\n",
    "    mean_values.append(np.mean(data[idx, 1]))\n",
    "    std_values.append(np.std(data[idx, 1]))\n",
    "\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(bin_centers, hist, width=bin_centers[1]-bin_centers[0], color='gray', alpha=0.5)\n",
    "ax.errorbar(bin_centers, mean_values, yerr=std_values, fmt='o', color='black')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title('Histogram with Mean and Standard Deviation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "class DSectDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load the list of event and image files\n",
    "        self.event_files = os.listdir(os.path.join(root_dir, 'events'))\n",
    "        self.image_files = os.listdir(os.path.join(root_dir, 'images'))\n",
    "        \n",
    "        # Sort the files to ensure they match up\n",
    "        self.event_files.sort()\n",
    "        self.image_files.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.event_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the event and image files for the given index\n",
    "        event_file = os.path.join(self.root_dir, 'events', self.event_files[idx])\n",
    "        image_file = os.path.join(self.root_dir, 'images', self.image_files[idx])\n",
    "        \n",
    "        # Load the event data\n",
    "        events = np.load(event_file)\n",
    "        \n",
    "        # Load the image data\n",
    "        image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Apply transformations to the data if provided\n",
    "        if self.transform:\n",
    "            events, image = self.transform((events, image))\n",
    "        \n",
    "        # Convert the data to PyTorch tensors\n",
    "        events = torch.from_numpy(events).float()\n",
    "        image = torch.from_numpy(image).float()\n",
    "        \n",
    "        return events, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = DSectDataset(root_dir='/path/to/dataset')\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Loop over the dataloader\n",
    "for events, image in dataloader:\n",
    "    # Do something with the event and image data\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    print(\"Hello, I am a MyClass!\")\n",
    "    a = 9\n",
    "    def __init__(self):\n",
    "        print(\"Hello, I am an instance of MyClass!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
