{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class SmoothingLayer(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super(SmoothingLayer, self).__init__(aggr='add')  # Use \"add\" aggregation.\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Pass messages between nodes.\n",
    "        edge_index,_ = add_self_loops(edge_index)\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # Compute the L1 norm of the input features for each edge of the graph.\n",
    "        # out =  (torch.sum(torch.pow(x_i - x_j,2),dim=1,keepdim=True))\n",
    "        out = torch.linalg.vector_norm(x_i - x_j, ord=2, dim=1,keepdim=True)\n",
    "        return out\n",
    "   \n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Return the L1 norm of the features for each edge of the graph.\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.pool import global_max_pool\n",
    "from torch_geometric.transforms import Cartesian\n",
    "\n",
    "# Define a simple graph with two nodes and one edge.\n",
    "edge_index = torch.tensor([[0, 1, 0, 2, 0, 3],\n",
    "                           [1, 0, 2, 0, 3, 0]], dtype=torch.long)\n",
    "x = torch.tensor([[1.0], [2.0], [3.0], [4.0]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "edge_attr = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0], [6.0]], dtype=torch.float)\n",
    "\n",
    "# Create an instance of our custom MessagePassing class.\n",
    "mp = torch_geometric.nn.conv.GCNConv(in_channels=1, out_channels=3)\n",
    "spConv = torch_geometric.nn.conv.SplineConv(in_channels=1, out_channels=3,dim = 1, kernel_size=2)\n",
    "sl = SmoothingLayer()\n",
    "\n",
    "# Perform a forward pass.\n",
    "\n",
    "x = spConv(x=data.x, edge_index=data.edge_index, edge_attr=edge_attr)\n",
    "x = mp(x=data.x, edge_index=data.edge_index)\n",
    "x = sl(x=x, edge_index=data.edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the optimizer to use for training.\n",
    "optimizer = torch.optim.Adam(mp.parameters(), lr=0.001)\n",
    "\n",
    "weights = []\n",
    "grads = []\n",
    "losses = []\n",
    "ops = []\n",
    "# Run the message passing algorithm for one iteration.\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    x = mp(x=data.x, edge_index=data.edge_index)\n",
    "    ops.append(x.clone().detach().cpu().numpy()[:,1:2])\n",
    "    x = sl(x=x, edge_index=data.edge_index)\n",
    "    x = global_max_pool(x=x, batch=data.batch)\n",
    "    loss = torch.sum(x)\n",
    "    losses.append(loss.clone().detach().cpu().numpy())\n",
    "\n",
    "    # Backpropagate the gradients and update the weights.\n",
    "    weights.append(mp.bias.clone().detach().cpu().numpy())\n",
    "    loss.backward()\n",
    "    grads.append(mp.lin.weight.grad.clone().detach().cpu().numpy())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plot each weight in the network\n",
    "weights_plot = [[w[i] for w in weights] for i in range(weights[0].shape[0])]\n",
    "grads_plot = [[g[i] for g in grads] for i in range(grads[0].shape[0])]\n",
    "losses_plot = [l for l in losses]\n",
    "ops_plot = [[o[i] for o in ops] for i in range(ops[0].shape[0])]\n",
    "\n",
    "# plot the elemts of grads_plot list in one plot\n",
    "for i in range(len(ops_plot)):\n",
    "    plt.plot(ops_plot[i])\n",
    "plt.show()\n",
    "\n",
    "# plot the elemts of weights_plot list in one plot\n",
    "for i in range(len(weights_plot)):\n",
    "    plt.plot(weights_plot[i])\n",
    "plt.show()\n",
    "\n",
    "# plot the elemts of grads_plot list in one plot\n",
    "for i in range(len(grads_plot)):\n",
    "    plt.plot(grads_plot[i])\n",
    "plt.show()\n",
    "\n",
    "# plot the elemts of losses_plot list in one plot\n",
    "plt.plot(losses_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import erdos_renyi_graph, remove_isolated_nodes, barabasi_albert_graph, to_undirected\n",
    "\n",
    "# Define the device to use for training.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Generate some random graph data.\n",
    "num_graphs = 1000\n",
    "num_edges = 4\n",
    "max_nodes = 100\n",
    "edge_prob = 0.2\n",
    "num_features = 12\n",
    "\n",
    "data_list = []\n",
    "\n",
    "\n",
    "for i in range(num_graphs):\n",
    "    num_nodes = torch.randint(1, max_nodes, size=(1,))[0]\n",
    "    # num_nodes = max_nodes\n",
    "    # Create a random graph with 10 nodes and a 20% probability of an edge between any two nodes,\n",
    "    # without isolated nodes.\n",
    "    # edge_index = barabasi_albert_graph(num_nodes = num_nodes, num_edges = num_edges)\n",
    "    edge_index = erdos_renyi_graph(num_nodes=num_nodes, edge_prob=edge_prob, directed=False)\n",
    "    # edge_index = to_undirected(edge_index)\n",
    "    edge_index, _, _ = remove_isolated_nodes(edge_index)\n",
    "    \n",
    "    # Create some random node features.\n",
    "    x = torch.randn(num_nodes, num_features)\n",
    "\n",
    "    # Create a data object for the graph.\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    data_list.append(data)\n",
    "\n",
    "# Create a data loader with batch size 16.\n",
    "loader = DataLoader(data_list, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.nn.pool import global_max_pool,global_mean_pool\n",
    "\n",
    "# Create an instance of our custom MessagePassing class.\n",
    "mp = torch_geometric.nn.conv.GCNConv(in_channels=num_features, out_channels=2).to(device)\n",
    "sl = SmoothingLayer()\n",
    "\n",
    "# Define the optimizer to use for training.\n",
    "optimizer = torch.optim.Adam(mp.parameters(), lr=0.001)\n",
    "\n",
    "weights = []\n",
    "losses = []\n",
    "grads = []\n",
    "\n",
    "for epoch in range(25):\n",
    "    loss_all = 0\n",
    "\n",
    "    # Iterate over the batches in the data loader.\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        # Perform a forward pass.\n",
    "        x = mp(x=data.x, edge_index=data.edge_index)\n",
    "        x = sl(x=x, edge_index=data.edge_index)\n",
    "        x = global_max_pool(x=x, batch=data.batch)\n",
    "        loss = torch.sum(x)\n",
    "        optimizer.zero_grad()\n",
    "        weights.append(mp.lin.weight.clone().detach().cpu().numpy())\n",
    "        losses.append(loss.item())\n",
    "        # mp.lin.weight.register_hook(lambda grad: print(grad))\n",
    "        # Backpropagate the gradients and update the weights.\n",
    "        loss.backward()\n",
    "        # print('after:', loss.grad)\n",
    "        grads.append(mp.lin.weight.grad.clone().detach().cpu().numpy())\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "\n",
    "    # Compute the average loss across all batches.\n",
    "    loss_all /= len(data_list)\n",
    "\n",
    "    # Print the average loss for this epoch.\n",
    "    print('Epoch {}, Loss {:.4f}'.format(epoch, loss_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
